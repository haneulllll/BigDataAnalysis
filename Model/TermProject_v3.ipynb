{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9698ac93-6ed2-45dd-b7d3-264dd265a148",
   "metadata": {},
   "source": [
    "## csv 데이터 기반 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eaf6e202-a51b-48f8-905f-7a287c87949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class AISPreprocessor:\n",
    "    # data_dir: 경로 데이터 파일(csv)이 존재하는 폴더 이름 \n",
    "    # input_seq_len: 참조할 이전 과거 정보(default: 10분)\n",
    "    # output_seq_len: 예측할 미래 정보(default: 1분)\n",
    "    def __init__(self, data_dir, input_seq_len=10, output_seq_len=1):\n",
    "        self.data_dir = data_dir\n",
    "        self.input_seq_len = input_seq_len\n",
    "        self.output_seq_len = output_seq_len\n",
    "\n",
    "        # 수동 설정된 범위로 MinMaxScaler 초기화\n",
    "        # 정규화 범위 설정\n",
    "        lat_range = (33.0, 38.0)\n",
    "        lon_range = (124.0, 132.0)\n",
    "        sog_range = (0.0, 100.0)\n",
    "        cog_range = (0.0, 360.0)\n",
    "        \n",
    "        # MinMaxScaler 수동 설정\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler.min_ = np.array([\n",
    "            -lat_range[0] / (lat_range[1] - lat_range[0]),\n",
    "            -lon_range[0] / (lon_range[1] - lon_range[0]),\n",
    "            -sog_range[0] / (sog_range[1] - sog_range[0]),\n",
    "            -cog_range[0] / (cog_range[1] - cog_range[0])\n",
    "        ])\n",
    "        self.scaler.scale_ = np.array([\n",
    "            1 / (lat_range[1] - lat_range[0]),\n",
    "            1 / (lon_range[1] - lon_range[0]),\n",
    "            1 / (sog_range[1] - sog_range[0]),\n",
    "            1 / (cog_range[1] - cog_range[0])\n",
    "        ])\n",
    "        self.scaler.feature_names_in_ = np.array(['위도', '경도', 'SOG', 'COG'])\n",
    "\n",
    "\n",
    "    def load_and_preprocess(self):\n",
    "        input_seqs = []\n",
    "        output_seqs = []\n",
    "        count = 1\n",
    "        for file in os.listdir(self.data_dir):\n",
    "            if file.endswith('.csv'):\n",
    "                print(f\"---------- {count}번째 파일 진행 중 ----------\")\n",
    "                count += 1\n",
    "                df = pd.read_csv(os.path.join(self.data_dir, file), encoding='cp949')\n",
    "                df = self._preprocess_single_file(df)\n",
    "                in_seqs, out_seqs = self._extract_sequences(df)\n",
    "                input_seqs.extend(in_seqs)\n",
    "                output_seqs.extend(out_seqs)\n",
    "\n",
    "        return np.array(input_seqs), np.array(output_seqs)\n",
    "\n",
    "    def _preprocess_single_file(self, df):\n",
    "        df = df[['일시', '위도', '경도', 'SOG', 'COG']].copy()\n",
    "        df['일시'] = pd.to_datetime(df['일시'])\n",
    "        # 일시 기준 데이터 sorting\n",
    "        df = df.sort_values('일시')\n",
    "        # NA 데이터 drop\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # 각 데이터를, 일시 기준 1분 별 보간법을 적용해 transform 적용 ------------------------------------\n",
    "        # 예: 01:00:04, 01:00:06, 01:00:16 데이터 -> 평균 -> 01:00:00(1시 0분)으로 한 샘플 생성\n",
    "        # 에: 01:01:05, 01:01:12, 01:01:35, 01:01:44 데이터 -> 평균 -> 01:01:00(1시 1분)으로 한 샘플 생성\n",
    "        # 평균을 적용하는 데이터는 위도, 경도, sog, cog 데이터 \n",
    "        df = df.set_index('일시').resample('1min').mean().interpolate()\n",
    "        df = df.reset_index()\n",
    "        # -----------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # 목적지 좌표: 마지막 위치\n",
    "        dest_lat = df['위도'].iloc[-1]\n",
    "        dest_lon = df['경도'].iloc[-1]\n",
    "        \n",
    "        # feature engineering을 위한 feature 저장 \n",
    "        df['dest_lat'] = dest_lat\n",
    "        df['dest_lon'] = dest_lon\n",
    "        return df\n",
    "\n",
    "    def _extract_sequences(self, df):\n",
    "        input_seqs = []\n",
    "        output_seqs = []\n",
    "    \n",
    "        total_len = self.input_seq_len + self.output_seq_len\n",
    "        for i in range(len(df) - total_len):\n",
    "            input_window = df.iloc[i:i+self.input_seq_len]\n",
    "            output_window = df.iloc[i+self.input_seq_len:i+total_len]\n",
    "    \n",
    "            # 입력: 위도, 경도, SOG, COG (정규화)\n",
    "            input_scaled = self.scaler.transform(input_window[['위도', '경도', 'SOG', 'COG']])\n",
    "            input_seq = input_scaled\n",
    "            # 출력: 위도, 경도, SOG, COG (정규화)\n",
    "            output_seq = self.scaler.transform(output_window[['위도', '경도', 'SOG', 'COG']])\n",
    "    \n",
    "            input_seqs.append(input_seq)\n",
    "            output_seqs.append(output_seq)\n",
    "    \n",
    "        return input_seqs, output_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38ea158b-4b68-4eb3-8d76-4a81d9200ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- 1번째 파일 진행 중 ----------\n",
      "---------- 2번째 파일 진행 중 ----------\n",
      "---------- 3번째 파일 진행 중 ----------\n",
      "---------- 4번째 파일 진행 중 ----------\n",
      "---------- 5번째 파일 진행 중 ----------\n",
      "---------- 6번째 파일 진행 중 ----------\n",
      "---------- 7번째 파일 진행 중 ----------\n",
      "---------- 8번째 파일 진행 중 ----------\n",
      "---------- 9번째 파일 진행 중 ----------\n",
      "---------- 10번째 파일 진행 중 ----------\n",
      "---------- 11번째 파일 진행 중 ----------\n",
      "---------- 12번째 파일 진행 중 ----------\n",
      "---------- 13번째 파일 진행 중 ----------\n",
      "---------- 14번째 파일 진행 중 ----------\n",
      "---------- 15번째 파일 진행 중 ----------\n",
      "---------- 16번째 파일 진행 중 ----------\n",
      "---------- 17번째 파일 진행 중 ----------\n",
      "---------- 18번째 파일 진행 중 ----------\n",
      "---------- 19번째 파일 진행 중 ----------\n",
      "---------- 20번째 파일 진행 중 ----------\n",
      "---------- 21번째 파일 진행 중 ----------\n",
      "---------- 22번째 파일 진행 중 ----------\n",
      "---------- 23번째 파일 진행 중 ----------\n",
      "---------- 24번째 파일 진행 중 ----------\n",
      "---------- 25번째 파일 진행 중 ----------\n",
      "---------- 26번째 파일 진행 중 ----------\n",
      "---------- 27번째 파일 진행 중 ----------\n",
      "---------- 28번째 파일 진행 중 ----------\n",
      "---------- 29번째 파일 진행 중 ----------\n",
      "---------- 30번째 파일 진행 중 ----------\n",
      "---------- 31번째 파일 진행 중 ----------\n",
      "---------- 32번째 파일 진행 중 ----------\n",
      "---------- 33번째 파일 진행 중 ----------\n",
      "---------- 34번째 파일 진행 중 ----------\n",
      "---------- 35번째 파일 진행 중 ----------\n",
      "---------- 36번째 파일 진행 중 ----------\n",
      "---------- 37번째 파일 진행 중 ----------\n",
      "---------- 38번째 파일 진행 중 ----------\n",
      "---------- 39번째 파일 진행 중 ----------\n",
      "Input sequences shape: (38701, 10, 4)\n",
      "Output sequences shape: (38701, 1, 4)\n",
      "\n",
      "Sample Input Sequence (첫 번째 샘플):\n",
      "[[0.86614926 0.2939715  0.199      0.72364198]\n",
      " [0.86595533 0.29309813 0.1992     0.72277778]\n",
      " [0.86573513 0.29216343 0.19807692 0.7125641 ]\n",
      " [0.86547722 0.2915362  0.19477778 0.6849537 ]\n",
      " [0.86490037 0.29071199 0.19611111 0.65876543]\n",
      " [0.86426933 0.28998146 0.1984     0.65411111]\n",
      " [0.86363767 0.28926229 0.1993     0.65366667]\n",
      " [0.862989   0.28855958 0.1991     0.6465    ]\n",
      " [0.862306   0.28785875 0.2001     0.64575   ]\n",
      " [0.86162481 0.28716664 0.20055556 0.64570988]]\n",
      "\n",
      "Sample Output Sequence (첫 번째 샘플):\n",
      "[[0.86093259 0.28646065 0.20066667 0.6454321 ]]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "# 데이터 디렉토리 경로 설정 (예: routes 폴더 안에 여러 개의 csv가 있는 경우)\n",
    "data_dir = './routes'\n",
    "# 전처리 객체 생성\n",
    "preprocessor = AISPreprocessor(data_dir)\n",
    "\n",
    "# 데이터 로드 및 전처리 실행\n",
    "input_seqs, output_seqs = preprocessor.load_and_preprocess()\n",
    "\n",
    "# 출력 확인\n",
    "print(\"Input sequences shape:\", input_seqs.shape)   # (num_samples, 10, 4)\n",
    "print(\"Output sequences shape:\", output_seqs.shape) # (num_samples, 1, 4)\n",
    "\n",
    "# 예시 데이터 출력 (첫 샘플)\n",
    "print(\"\\nSample Input Sequence (첫 번째 샘플):\")\n",
    "print(input_seqs[5])\n",
    "\n",
    "print(\"\\nSample Output Sequence (첫 번째 샘플):\")\n",
    "print(output_seqs[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cadb13-0e76-4bb8-aff7-c70f3aa0a9c4",
   "metadata": {},
   "source": [
    "## 경로 예측모델 \n",
    "\n",
    "- 입력 시퀀스 (위도, 경도, SOG, COG, (목적지-현재위치 위도), (목적지-현재위치 경도))\n",
    "  \n",
    "      ↓\n",
    "  \n",
    "- Linear 프로젝션 (input_size → d_model)\n",
    "\n",
    "  \n",
    "      ↓\n",
    "\n",
    "  \n",
    "- Positional Encoding 추가\n",
    "\n",
    "  \n",
    "      ↓\n",
    "\n",
    "  \n",
    "- Transformer Encoder (Multi-head Self Attention, FeedForward)\n",
    "\n",
    "  \n",
    "      ↓\n",
    "\n",
    "  \n",
    "- Decoder (MLP)\n",
    "\n",
    "  \n",
    "      ↓\n",
    "\n",
    "  \n",
    "- 출력 (예: 다음 시점의 위도, 경도, SOG, COG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9aa290fe-fab0-46ad-862f-0906c9a452bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# 위도/경도 오차 부분에 중점을 두기 위한 사용자 설정 LOSS FUNCTION\n",
    "class CustomTrajectoryLoss(nn.Module):\n",
    "    def __init__(self, weight_location = 0.8):\n",
    "        super().__init__()\n",
    "        self.weight_location = weight_location\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = y_pred.squeeze(1)\n",
    "        y_true = y_true.squeeze(1)\n",
    "        # y_pred, y_true: (batch_size, 4) → [lat, lon, SOG, COG]\n",
    "        pred_lat, pred_lon = y_pred[:, 0], y_pred[:, 1]\n",
    "        true_lat, true_lon = y_true[:, 0], y_true[:, 1]\n",
    "        pred_sog, pred_cog = y_pred[:, 2], y_pred[:, 3]\n",
    "        true_sog, true_cog = y_true[:, 2], y_true[:, 3]\n",
    "        \n",
    "        # 1. 위도/경도 loss\n",
    "        location_loss = 0.5*torch.square(pred_lat-true_lat) + 0.5*torch.square(pred_lon-true_lon)\n",
    "        location_loss = location_loss.mean()\n",
    "        # 2. sog, cog loss\n",
    "        else_loss = 0.5*torch.square(pred_sog-true_sog) + 0.5*torch.square(pred_cog-true_cog)\n",
    "        else_loss = else_loss.mean()\n",
    "        # 3. 합산 Loss\n",
    "        total_loss = self.weight_location*location_loss + (1-self.weight_location)*else_loss\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0da5701b-decf-46d5-b326-77f0a938e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "## 위치 정보 전달을 위한 정적 포지셔널 인코딩\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()  # (max_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # even index\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # odd index\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, d_model)\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x\n",
    "\n",
    "\n",
    "### 시계열 학습을 위한 트랜스포머 회귀 모델\n",
    "## d_model: 주목할 input의 특징들\n",
    "## nhead: 멀티 헤드 어텐션 헤드 수\n",
    "## dim_feedforward: FFN 차원 수\n",
    "# dim_feedforward = d_model * 4\n",
    "# d_model % n_head = 0\n",
    "class TransformerPredictor(nn.Module):\n",
    "    def __init__(self, input_size=4, output_size=4, d_model=256, nhead=16, num_layers=6, dim_feedforward=1024, dropout=0.2):\n",
    "        super(TransformerPredictor, self).__init__()\n",
    "\n",
    "        self.input_proj = nn.Linear(input_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model) # 포지셔널 인코딩을 통해 순서 정보를 추가\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, # input의 특징들\n",
    "            nhead=nhead, # 멀티 헤드 어텐션 헤드 수\n",
    "            dim_feedforward=dim_feedforward, # FFN 차원 수, 기본 2048\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\", # default=\"relu\"\n",
    "        )\n",
    "        # 인코더\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        # MLP 기반 디코더\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(d_model, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size)\n",
    "        x = self.input_proj(x)  # (batch_size, seq_len, d_model)\n",
    "        x = self.pos_encoder(x)  # (batch_size, seq_len, d_model)\n",
    "        x = self.transformer_encoder(x)  # (batch_size, seq_len, d_model)\n",
    "        # 자가회귀 예측: 마지막 타임스텝의 출력만 사용\n",
    "        x_last = x[:, -1, :]  # (batch_size, d_model)\n",
    "        out = self.decoder(x_last)  # (batch_size, output_size)\n",
    "\n",
    "        # 차원을 맞추기 위해 seq_len=1 축을 다시 추가\n",
    "        out = out.unsqueeze(1)  # (batch_size, 1, output_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17497418-ed6e-49e4-b9d8-9ba78a7a36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_transformer_model(model, train_data, val_data=None, num_epochs=50, batch_size=128, learning_rate=1e-4, device='cpu'):\n",
    "    \"\"\"\n",
    "    model: TransformerPredictor 모델\n",
    "    train_data: (x_train_tensor, y_train_tensor)\n",
    "    val_data: (x_val_tensor, y_val_tensor)\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    ## train_data를 train / validation data로 분할 --------------------------------\n",
    "    x_train, y_train = train_data\n",
    "    x_train_f, x_val, y_train_f, y_val = train_test_split(\n",
    "        x_train, y_train, test_size=0.1, random_state=42\n",
    "    )\n",
    "\n",
    "    \n",
    "    train_dataset = TensorDataset(x_train_f, y_train_f)\n",
    "    val_data = (x_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # ----------------------------------------------------------------------------\n",
    "    \n",
    "    # Loss & Optimizer\n",
    "    #criterion = nn.MSELoss()\n",
    "    criterion = CustomTrajectoryLoss(weight_location=0.9)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1) # gradient exploding 방지 \n",
    "            outputs = model(batch_x)  # (batch, seq_len, output_size)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] Train Loss: {avg_loss:.6f}\")\n",
    "\n",
    "        # Validation 진행\n",
    "        if val_data is not None:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x_val, y_val = val_data\n",
    "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                val_outputs = model(x_val)\n",
    "                val_loss = criterion(val_outputs, y_val)\n",
    "                print(f\"           ↳ Val Loss: {val_loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc8327fc-fd5b-4633-9fc5-69a12d9937ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/50] Train Loss: 0.018544\n",
      "           ↳ Val Loss: 0.000681\n",
      "[Epoch 2/50] Train Loss: 0.000543\n",
      "           ↳ Val Loss: 0.000454\n",
      "[Epoch 3/50] Train Loss: 0.000365\n",
      "           ↳ Val Loss: 0.000221\n",
      "[Epoch 4/50] Train Loss: 0.000224\n",
      "           ↳ Val Loss: 0.000197\n",
      "[Epoch 5/50] Train Loss: 0.000179\n",
      "           ↳ Val Loss: 0.000346\n",
      "[Epoch 6/50] Train Loss: 0.000145\n",
      "           ↳ Val Loss: 0.000084\n",
      "[Epoch 7/50] Train Loss: 0.000102\n",
      "           ↳ Val Loss: 0.000173\n",
      "[Epoch 8/50] Train Loss: 0.000082\n",
      "           ↳ Val Loss: 0.000105\n",
      "[Epoch 9/50] Train Loss: 0.000072\n",
      "           ↳ Val Loss: 0.000181\n",
      "[Epoch 10/50] Train Loss: 0.000062\n",
      "           ↳ Val Loss: 0.000070\n",
      "[Epoch 11/50] Train Loss: 0.000058\n",
      "           ↳ Val Loss: 0.000097\n",
      "[Epoch 12/50] Train Loss: 0.000051\n",
      "           ↳ Val Loss: 0.000117\n",
      "[Epoch 13/50] Train Loss: 0.000046\n",
      "           ↳ Val Loss: 0.000082\n",
      "[Epoch 14/50] Train Loss: 0.000045\n",
      "           ↳ Val Loss: 0.000020\n",
      "[Epoch 15/50] Train Loss: 0.000041\n",
      "           ↳ Val Loss: 0.000120\n",
      "[Epoch 16/50] Train Loss: 0.000041\n",
      "           ↳ Val Loss: 0.000065\n",
      "[Epoch 17/50] Train Loss: 0.000037\n",
      "           ↳ Val Loss: 0.000033\n",
      "[Epoch 18/50] Train Loss: 0.000034\n",
      "           ↳ Val Loss: 0.000030\n",
      "[Epoch 19/50] Train Loss: 0.000038\n",
      "           ↳ Val Loss: 0.000175\n",
      "[Epoch 20/50] Train Loss: 0.000030\n",
      "           ↳ Val Loss: 0.000059\n",
      "[Epoch 21/50] Train Loss: 0.000033\n",
      "           ↳ Val Loss: 0.000014\n",
      "[Epoch 22/50] Train Loss: 0.000032\n",
      "           ↳ Val Loss: 0.000027\n",
      "[Epoch 23/50] Train Loss: 0.000029\n",
      "           ↳ Val Loss: 0.000051\n",
      "[Epoch 24/50] Train Loss: 0.000028\n",
      "           ↳ Val Loss: 0.000065\n",
      "[Epoch 25/50] Train Loss: 0.000025\n",
      "           ↳ Val Loss: 0.000023\n",
      "[Epoch 26/50] Train Loss: 0.000030\n",
      "           ↳ Val Loss: 0.000026\n",
      "[Epoch 27/50] Train Loss: 0.000026\n",
      "           ↳ Val Loss: 0.000017\n",
      "[Epoch 28/50] Train Loss: 0.000028\n",
      "           ↳ Val Loss: 0.000031\n",
      "[Epoch 29/50] Train Loss: 0.000024\n",
      "           ↳ Val Loss: 0.000122\n",
      "[Epoch 30/50] Train Loss: 0.000027\n",
      "           ↳ Val Loss: 0.000021\n",
      "[Epoch 31/50] Train Loss: 0.000023\n",
      "           ↳ Val Loss: 0.000013\n",
      "[Epoch 32/50] Train Loss: 0.000024\n",
      "           ↳ Val Loss: 0.000099\n",
      "[Epoch 33/50] Train Loss: 0.000023\n",
      "           ↳ Val Loss: 0.000049\n",
      "[Epoch 34/50] Train Loss: 0.000024\n",
      "           ↳ Val Loss: 0.000051\n",
      "[Epoch 35/50] Train Loss: 0.000022\n",
      "           ↳ Val Loss: 0.000020\n",
      "[Epoch 36/50] Train Loss: 0.000021\n",
      "           ↳ Val Loss: 0.000030\n",
      "[Epoch 37/50] Train Loss: 0.000021\n",
      "           ↳ Val Loss: 0.000058\n",
      "[Epoch 38/50] Train Loss: 0.000021\n",
      "           ↳ Val Loss: 0.000015\n",
      "[Epoch 39/50] Train Loss: 0.000019\n",
      "           ↳ Val Loss: 0.000055\n",
      "[Epoch 40/50] Train Loss: 0.000020\n",
      "           ↳ Val Loss: 0.000021\n",
      "[Epoch 41/50] Train Loss: 0.000020\n",
      "           ↳ Val Loss: 0.000060\n",
      "[Epoch 42/50] Train Loss: 0.000019\n",
      "           ↳ Val Loss: 0.000020\n",
      "[Epoch 43/50] Train Loss: 0.000020\n",
      "           ↳ Val Loss: 0.000015\n",
      "[Epoch 44/50] Train Loss: 0.000021\n",
      "           ↳ Val Loss: 0.000021\n",
      "[Epoch 45/50] Train Loss: 0.000019\n",
      "           ↳ Val Loss: 0.000018\n",
      "[Epoch 46/50] Train Loss: 0.000017\n",
      "           ↳ Val Loss: 0.000013\n",
      "[Epoch 47/50] Train Loss: 0.000018\n",
      "           ↳ Val Loss: 0.000033\n",
      "[Epoch 48/50] Train Loss: 0.000018\n",
      "           ↳ Val Loss: 0.000038\n",
      "[Epoch 49/50] Train Loss: 0.000017\n",
      "           ↳ Val Loss: 0.000021\n",
      "[Epoch 50/50] Train Loss: 0.000016\n",
      "           ↳ Val Loss: 0.000012\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = TransformerPredictor(input_size=4, output_size=4)\n",
    "\n",
    "# numpy → torch tensor로 변환\n",
    "input_tensor = torch.tensor(input_seqs, dtype=torch.float32)\n",
    "output_tensor = torch.tensor(output_seqs, dtype=torch.float32)\n",
    "# 학습\n",
    "train_transformer_model(model, (input_tensor, output_tensor), num_epochs=50, device='cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a996745-1886-480a-9290-3680d011abd9",
   "metadata": {},
   "source": [
    "## 자가회귀 예측 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76b44b5b-29ac-42ec-a804-9ffacfa377b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "torch.save(model, \"route_predictor2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ed67c4e-ec44-4b2b-ae1c-15dabe4f1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "## 자가회귀를 위한 함수\n",
    "## 선박의 예상 경로가 목적지 인근 부근이 될 때까지 모델의 예측 반복 / 임계값: max_steps\n",
    "def predict_autoregressive(model, initial_seq, dest_lat, dest_lon, scaler, max_steps, distance_threshold=0.1):\n",
    "    \"\"\"\n",
    "    model: 학습된 Transformer 모델\n",
    "    initial_seq: 초기 입력 시퀀스 (torch.Tensor), shape: (1, 10, 4), 정규화된 값이 들어와야 됨.\n",
    "    dest_lat, dest_lon: 목적지 좌표\n",
    "    scaler: 학습에 사용한 MinMaxScaler\n",
    "    device: 'cpu' or 'cuda'\n",
    "    max_steps: 최대 예측 스텝 수\n",
    "    distance_threshold: 도착지와 거리 차가 이 값 이하이면 도착으로 간주\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    input_seq = initial_seq.clone()  # input_seq의 복사 생성\n",
    "    all_preds = []\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        input_tensor = input_seq\n",
    "        # 예측\n",
    "        with torch.no_grad():\n",
    "            pred = model(input_tensor).squeeze(0).cpu().numpy()  # (seq_len, output_size)\n",
    "\n",
    "        all_preds.append(pred)\n",
    "\n",
    "        ## 예상 경로 도착지 도달 여부 확인 매커니즘 ----------------------------------------------------------\n",
    "        # 예측한 경로값 역정규화\n",
    "        pred_denorm = scaler.inverse_transform(pred.reshape(1, -1))[0][:4]\n",
    "        pred_lat, pred_lon = pred_denorm[:2]\n",
    "\n",
    "        # 디버깅 코드\n",
    "        if(step % 10 == 0):\n",
    "            print(f\"[Step {step+1}] Predicted: ({pred_lat:.5f}, {pred_lon:.5f}) | \"\n",
    "                  f\"Target: ({dest_lat:.5f}, {dest_lon:.5f}) | \"\n",
    "                  f\"ΔLat: {abs(pred_lat - dest_lat):.5f}, ΔLon: {abs(pred_lon - dest_lon):.5f}\")\n",
    "    \n",
    "    \n",
    "        if abs(pred_lat - dest_lat) < distance_threshold and abs(pred_lon - dest_lon) < distance_threshold:\n",
    "            print(f\"🚢 목적지 도달 - Step: {step + 1}, {int(step/60)} 시간 {step%60} 분 소요\")\n",
    "            break\n",
    "\n",
    "        ## ------------------------------------------------------------------------------------------------\n",
    "            \n",
    "        ## 입력 시퀀스 업데이트: 다음 입력을 만듦 -----------------------------------------------\n",
    "        \n",
    "        # 정규화된 lat/lon/sog/cog (4개만 사용)\n",
    "        pred_norm = pred.reshape(1, -1)[0]  # (4,)\n",
    "        next_input = pred_norm\n",
    "        # ---------------------------------------\n",
    "        # 기존 시퀀스에서 가장 앞 데이터 제거, 새 데이터 추가\n",
    "        input_seq_np = input_seq.squeeze(0).numpy()\n",
    "        input_seq_np = np.vstack([input_seq_np[1:], next_input])\n",
    "        input_seq = torch.tensor([input_seq_np], dtype=torch.float32)  # (1, 10, 4)\n",
    "        # ----------------------------------------------------------------------\n",
    "    return np.array(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b79886be-358d-451c-a36f-8efe56d1a0ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1] Predicted: (37.37479, 126.33269) | Target: (33.55000, 126.55000) | ΔLat: 3.82479, ΔLon: 0.21732\n",
      "[Step 11] Predicted: (37.36676, 126.31253) | Target: (33.55000, 126.55000) | ΔLat: 3.81676, ΔLon: 0.23747\n",
      "[Step 21] Predicted: (37.36053, 126.29897) | Target: (33.55000, 126.55000) | ΔLat: 3.81053, ΔLon: 0.25104\n",
      "[Step 31] Predicted: (37.35086, 126.28451) | Target: (33.55000, 126.55000) | ΔLat: 3.80086, ΔLon: 0.26550\n",
      "[Step 41] Predicted: (37.33782, 126.26781) | Target: (33.55000, 126.55000) | ΔLat: 3.78782, ΔLon: 0.28219\n",
      "[Step 51] Predicted: (37.31884, 126.24615) | Target: (33.55000, 126.55000) | ΔLat: 3.76884, ΔLon: 0.30385\n",
      "[Step 61] Predicted: (37.28115, 126.23109) | Target: (33.55000, 126.55000) | ΔLat: 3.73115, ΔLon: 0.31891\n",
      "[Step 71] Predicted: (37.24285, 126.21770) | Target: (33.55000, 126.55000) | ΔLat: 3.69285, ΔLon: 0.33231\n",
      "[Step 81] Predicted: (37.21215, 126.19505) | Target: (33.55000, 126.55000) | ΔLat: 3.66215, ΔLon: 0.35495\n",
      "[Step 91] Predicted: (37.18034, 126.17152) | Target: (33.55000, 126.55000) | ΔLat: 3.63034, ΔLon: 0.37849\n",
      "[Step 101] Predicted: (37.14354, 126.14513) | Target: (33.55000, 126.55000) | ΔLat: 3.59354, ΔLon: 0.40488\n",
      "[Step 111] Predicted: (37.09774, 126.11369) | Target: (33.55000, 126.55000) | ΔLat: 3.54774, ΔLon: 0.43632\n",
      "[Step 121] Predicted: (37.04093, 126.07668) | Target: (33.55000, 126.55000) | ΔLat: 3.49093, ΔLon: 0.47333\n",
      "[Step 131] Predicted: (36.97523, 126.03658) | Target: (33.55000, 126.55000) | ΔLat: 3.42524, ΔLon: 0.51342\n",
      "[Step 141] Predicted: (36.90511, 125.99711) | Target: (33.55000, 126.55000) | ΔLat: 3.35511, ΔLon: 0.55289\n",
      "[Step 151] Predicted: (36.83342, 125.96037) | Target: (33.55000, 126.55000) | ΔLat: 3.28342, ΔLon: 0.58964\n",
      "[Step 161] Predicted: (36.76086, 125.92664) | Target: (33.55000, 126.55000) | ΔLat: 3.21086, ΔLon: 0.62336\n",
      "[Step 171] Predicted: (36.68707, 125.89548) | Target: (33.55000, 126.55000) | ΔLat: 3.13707, ΔLon: 0.65452\n",
      "[Step 181] Predicted: (36.61136, 125.86623) | Target: (33.55000, 126.55000) | ΔLat: 3.06136, ΔLon: 0.68378\n",
      "[Step 191] Predicted: (36.53288, 125.83825) | Target: (33.55000, 126.55000) | ΔLat: 2.98288, ΔLon: 0.71175\n",
      "[Step 201] Predicted: (36.45093, 125.81075) | Target: (33.55000, 126.55000) | ΔLat: 2.90093, ΔLon: 0.73926\n",
      "[Step 211] Predicted: (36.37055, 125.77628) | Target: (33.55000, 126.55000) | ΔLat: 2.82055, ΔLon: 0.77372\n",
      "[Step 221] Predicted: (36.28930, 125.74797) | Target: (33.55000, 126.55000) | ΔLat: 2.73930, ΔLon: 0.80203\n",
      "[Step 231] Predicted: (36.21066, 125.72710) | Target: (33.55000, 126.55000) | ΔLat: 2.66066, ΔLon: 0.82291\n",
      "[Step 241] Predicted: (36.13502, 125.70921) | Target: (33.55000, 126.55000) | ΔLat: 2.58502, ΔLon: 0.84080\n",
      "[Step 251] Predicted: (36.06195, 125.69343) | Target: (33.55000, 126.55000) | ΔLat: 2.51195, ΔLon: 0.85658\n",
      "[Step 261] Predicted: (35.99114, 125.67956) | Target: (33.55000, 126.55000) | ΔLat: 2.44114, ΔLon: 0.87045\n",
      "[Step 271] Predicted: (35.92237, 125.66756) | Target: (33.55000, 126.55000) | ΔLat: 2.37237, ΔLon: 0.88245\n",
      "[Step 281] Predicted: (35.85540, 125.65735) | Target: (33.55000, 126.55000) | ΔLat: 2.30540, ΔLon: 0.89265\n",
      "[Step 291] Predicted: (35.78997, 125.64890) | Target: (33.55000, 126.55000) | ΔLat: 2.23997, ΔLon: 0.90111\n",
      "[Step 301] Predicted: (35.72574, 125.64213) | Target: (33.55000, 126.55000) | ΔLat: 2.17574, ΔLon: 0.90788\n",
      "[Step 311] Predicted: (35.66235, 125.63700) | Target: (33.55000, 126.55000) | ΔLat: 2.11235, ΔLon: 0.91300\n",
      "[Step 321] Predicted: (35.59945, 125.63348) | Target: (33.55000, 126.55000) | ΔLat: 2.04945, ΔLon: 0.91652\n",
      "[Step 331] Predicted: (35.53664, 125.63155) | Target: (33.55000, 126.55000) | ΔLat: 1.98664, ΔLon: 0.91846\n",
      "[Step 341] Predicted: (35.47367, 125.63120) | Target: (33.55000, 126.55000) | ΔLat: 1.92368, ΔLon: 0.91881\n",
      "[Step 351] Predicted: (35.41042, 125.63248) | Target: (33.55000, 126.55000) | ΔLat: 1.86042, ΔLon: 0.91752\n",
      "[Step 361] Predicted: (35.34702, 125.63551) | Target: (33.55000, 126.55000) | ΔLat: 1.79702, ΔLon: 0.91449\n",
      "[Step 371] Predicted: (35.28393, 125.64042) | Target: (33.55000, 126.55000) | ΔLat: 1.73393, ΔLon: 0.90958\n",
      "[Step 381] Predicted: (35.22189, 125.64731) | Target: (33.55000, 126.55000) | ΔLat: 1.67189, ΔLon: 0.90269\n",
      "[Step 391] Predicted: (35.16180, 125.65612) | Target: (33.55000, 126.55000) | ΔLat: 1.61180, ΔLon: 0.89388\n",
      "[Step 401] Predicted: (35.10458, 125.66662) | Target: (33.55000, 126.55000) | ΔLat: 1.55458, ΔLon: 0.88338\n",
      "[Step 411] Predicted: (35.05108, 125.67833) | Target: (33.55000, 126.55000) | ΔLat: 1.50108, ΔLon: 0.87167\n",
      "[Step 421] Predicted: (35.00203, 125.69070) | Target: (33.55000, 126.55000) | ΔLat: 1.45203, ΔLon: 0.85930\n",
      "[Step 431] Predicted: (34.95793, 125.70313) | Target: (33.55000, 126.55000) | ΔLat: 1.40793, ΔLon: 0.84687\n",
      "[Step 441] Predicted: (34.91906, 125.71513) | Target: (33.55000, 126.55000) | ΔLat: 1.36906, ΔLon: 0.83487\n",
      "[Step 451] Predicted: (34.88540, 125.72633) | Target: (33.55000, 126.55000) | ΔLat: 1.33540, ΔLon: 0.82368\n",
      "[Step 461] Predicted: (34.85561, 125.74014) | Target: (33.55000, 126.55000) | ΔLat: 1.30561, ΔLon: 0.80987\n",
      "[Step 471] Predicted: (34.82576, 125.75894) | Target: (33.55000, 126.55000) | ΔLat: 1.27576, ΔLon: 0.79106\n",
      "[Step 481] Predicted: (34.79433, 125.77933) | Target: (33.55000, 126.55000) | ΔLat: 1.24434, ΔLon: 0.77068\n",
      "[Step 491] Predicted: (34.76113, 125.80106) | Target: (33.55000, 126.55000) | ΔLat: 1.21113, ΔLon: 0.74895\n",
      "[Step 501] Predicted: (34.72612, 125.82438) | Target: (33.55000, 126.55000) | ΔLat: 1.17612, ΔLon: 0.72562\n",
      "[Step 511] Predicted: (34.68931, 125.84939) | Target: (33.55000, 126.55000) | ΔLat: 1.13931, ΔLon: 0.70061\n",
      "[Step 521] Predicted: (34.65073, 125.87614) | Target: (33.55000, 126.55000) | ΔLat: 1.10073, ΔLon: 0.67386\n",
      "[Step 531] Predicted: (34.61056, 125.90469) | Target: (33.55000, 126.55000) | ΔLat: 1.06056, ΔLon: 0.64531\n",
      "[Step 541] Predicted: (34.56903, 125.93501) | Target: (33.55000, 126.55000) | ΔLat: 1.01903, ΔLon: 0.61499\n",
      "[Step 551] Predicted: (34.52652, 125.96705) | Target: (33.55000, 126.55000) | ΔLat: 0.97652, ΔLon: 0.58295\n",
      "[Step 561] Predicted: (34.48349, 126.00061) | Target: (33.55000, 126.55000) | ΔLat: 0.93349, ΔLon: 0.54939\n",
      "[Step 571] Predicted: (34.44048, 126.03543) | Target: (33.55000, 126.55000) | ΔLat: 0.89048, ΔLon: 0.51457\n",
      "[Step 581] Predicted: (34.39812, 126.07108) | Target: (33.55000, 126.55000) | ΔLat: 0.84812, ΔLon: 0.47893\n",
      "[Step 591] Predicted: (34.35700, 126.10704) | Target: (33.55000, 126.55000) | ΔLat: 0.80700, ΔLon: 0.44296\n",
      "[Step 601] Predicted: (34.31766, 126.14278) | Target: (33.55000, 126.55000) | ΔLat: 0.76766, ΔLon: 0.40723\n",
      "[Step 611] Predicted: (34.28054, 126.17776) | Target: (33.55000, 126.55000) | ΔLat: 0.73055, ΔLon: 0.37225\n",
      "[Step 621] Predicted: (34.24592, 126.21154) | Target: (33.55000, 126.55000) | ΔLat: 0.69592, ΔLon: 0.33846\n",
      "[Step 631] Predicted: (34.21394, 126.24376) | Target: (33.55000, 126.55000) | ΔLat: 0.66394, ΔLon: 0.30624\n",
      "[Step 641] Predicted: (34.18465, 126.27415) | Target: (33.55000, 126.55000) | ΔLat: 0.63465, ΔLon: 0.27585\n",
      "[Step 651] Predicted: (34.15800, 126.30251) | Target: (33.55000, 126.55000) | ΔLat: 0.60800, ΔLon: 0.24750\n",
      "[Step 661] Predicted: (34.13033, 126.32890) | Target: (33.55000, 126.55000) | ΔLat: 0.58033, ΔLon: 0.22111\n",
      "[Step 671] Predicted: (34.10136, 126.35493) | Target: (33.55000, 126.55000) | ΔLat: 0.55136, ΔLon: 0.19508\n",
      "[Step 681] Predicted: (34.06824, 126.38008) | Target: (33.55000, 126.55000) | ΔLat: 0.51825, ΔLon: 0.16992\n",
      "[Step 691] Predicted: (34.02985, 126.40799) | Target: (33.55000, 126.55000) | ΔLat: 0.47985, ΔLon: 0.14201\n",
      "[Step 701] Predicted: (33.99405, 126.42998) | Target: (33.55000, 126.55000) | ΔLat: 0.44405, ΔLon: 0.12003\n",
      "[Step 711] Predicted: (33.96664, 126.44463) | Target: (33.55000, 126.55000) | ΔLat: 0.41665, ΔLon: 0.10538\n",
      "[Step 721] Predicted: (33.94425, 126.45531) | Target: (33.55000, 126.55000) | ΔLat: 0.39425, ΔLon: 0.09469\n",
      "[Step 731] Predicted: (33.92224, 126.46355) | Target: (33.55000, 126.55000) | ΔLat: 0.37224, ΔLon: 0.08646\n",
      "[Step 741] Predicted: (33.89984, 126.47165) | Target: (33.55000, 126.55000) | ΔLat: 0.34984, ΔLon: 0.07835\n",
      "[Step 751] Predicted: (33.87618, 126.48024) | Target: (33.55000, 126.55000) | ΔLat: 0.32618, ΔLon: 0.06976\n",
      "[Step 761] Predicted: (33.85012, 126.48975) | Target: (33.55000, 126.55000) | ΔLat: 0.30012, ΔLon: 0.06026\n",
      "[Step 771] Predicted: (33.82004, 126.50077) | Target: (33.55000, 126.55000) | ΔLat: 0.27004, ΔLon: 0.04923\n",
      "[Step 781] Predicted: (33.78353, 126.51414) | Target: (33.55000, 126.55000) | ΔLat: 0.23353, ΔLon: 0.03586\n",
      "[Step 791] Predicted: (33.73688, 126.53094) | Target: (33.55000, 126.55000) | ΔLat: 0.18688, ΔLon: 0.01906\n",
      "[Step 801] Predicted: (33.67550, 126.55173) | Target: (33.55000, 126.55000) | ΔLat: 0.12550, ΔLon: 0.00173\n",
      "🚢 목적지 도달 - Step: 805, 13 시간 24 분 소요\n"
     ]
    }
   ],
   "source": [
    "from math import atan2, sqrt, degrees\n",
    "\n",
    "## 초기 10분 시퀀스\n",
    "# 예시: 특정 CSV 파일에서 인천항 출발 경로 하나 로드\n",
    "pre = AISPreprocessor(data_dir='routes', input_seq_len=10, output_seq_len=1)\n",
    "\n",
    "df = pd.read_csv('routes/route_12_202004.csv', encoding='cp949', parse_dates=['일시'])\n",
    "df = pre._preprocess_single_file(df)\n",
    "initial_seq = df.iloc[:10]\n",
    "\n",
    "# MinMaxScaler 수동 설정 ----------------------------------------------------------\n",
    "# 정규화 범위 설정\n",
    "lat_range = (33.0, 38.0)\n",
    "lon_range = (124.0, 132.0)\n",
    "sog_range = (0.0, 100.0)\n",
    "cog_range = (0.0, 360.0)\n",
    "\n",
    "input_scaler = MinMaxScaler()\n",
    "input_scaler.min_ = np.array([\n",
    "    -lat_range[0] / (lat_range[1] - lat_range[0]),\n",
    "    -lon_range[0] / (lon_range[1] - lon_range[0]),\n",
    "    -sog_range[0] / (sog_range[1] - sog_range[0]),\n",
    "    -cog_range[0] / (cog_range[1] - cog_range[0])\n",
    "])\n",
    "input_scaler.scale_ = np.array([\n",
    "    1 / (lat_range[1] - lat_range[0]),\n",
    "    1 / (lon_range[1] - lon_range[0]),\n",
    "    1 / (sog_range[1] - sog_range[0]),\n",
    "    1 / (cog_range[1] - cog_range[0])\n",
    "])\n",
    "input_scaler.feature_names_in_ = np.array(['위도', '경도', 'SOG', 'COG'])\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# 목적지 좌표 설정 - 제주항\n",
    "dest_lat = 33.55  \n",
    "dest_lon = 126.55  \n",
    "\n",
    "# 입력 시퀀스 생성\n",
    "test_input_seq = []\n",
    "for _, row in initial_seq.iterrows():\n",
    "    # 1. 정규화된 위도, 경도, SOG, COG\n",
    "    scaled = input_scaler.transform([[row['위도'], row['경도'], row['SOG'], row['COG']]])[0]\n",
    "\n",
    "    # 4. 최종 입력 벡터 구성 (4차원)\n",
    "    input_row = list(scaled)\n",
    "    test_input_seq.append(input_row)\n",
    "\n",
    "test_input_seq = torch.tensor([test_input_seq], dtype=torch.float32)  # (1, 10, 4)\n",
    "\n",
    "# 목적지 좌표 설정\n",
    "destination_lat = dest_lat\n",
    "destination_lon = dest_lon\n",
    "scaler = input_scaler\n",
    "\n",
    "# 예측 실행\n",
    "preds = predict_autoregressive(\n",
    "    model=model,                      # 학습된 Transformer 모델\n",
    "    initial_seq=test_input_seq,       # 초기 입력 시퀀스 \n",
    "    dest_lat=destination_lat,         # 목적지 위도\n",
    "    dest_lon=destination_lon,         # 목적지 경도\n",
    "    scaler=scaler,                    # 학습에 사용된 MinMaxScaler                 \n",
    "    max_steps=1200                    # 예측할 시간 길이 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "347bd929-75ca-447b-945c-5a039768e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_preds(preds, scaler):\n",
    "    \"\"\"\n",
    "    역정규화를 수행하여 원래의 값으로 변환\n",
    "    preds: 예측된 값들 (numpy 배열), shape: (steps, output_size)\n",
    "    scaler: 학습에 사용된 MinMaxScaler\n",
    "    \"\"\"\n",
    "    # 위도, 경도, SOG, COG 값만 역정규화\n",
    "    preds_unscaled = preds.copy()  # 예측된 값을 복사\n",
    "\n",
    "    # 위도, 경도, SOG, COG를 역정규화\n",
    "    preds_unscaled[:, :4] = scaler.inverse_transform(preds_unscaled[:, :4])  # 역정규화\n",
    "    return preds_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61027563-5b24-4e9e-a6d7-58765434ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import AntPath\n",
    "\n",
    "def visualize_route(initial_seq, preds_inverse, dest_lat, dest_lon):\n",
    "    \"\"\"\n",
    "    예측된 경로를 시각화하는 함수\n",
    "    initial_seq: 초기 입력 시퀀스 (numpy 배열), shape: (10, 6)\n",
    "    preds_inverse: 역정규화된 예측 결과, shape: (steps, 4)\n",
    "    dest_lat, dest_lon: 목적지 좌표\n",
    "    \"\"\"\n",
    "    # 초기 위치\n",
    "    start = initial_seq[0, 0][:4]\n",
    "    start = scaler.inverse_transform([start])\n",
    "    start_lat = start[0][0] \n",
    "    start_lon = start[0][1]\n",
    "    # 지도 생성 (출발지와 목적지가 모두 보이도록 설정)\n",
    "    route_map = folium.Map(location=[start_lat, start_lon], zoom_start=6)\n",
    "\n",
    "    # 시작점, 목적지 마커 추가\n",
    "    folium.Marker([start_lat, start_lon], tooltip='Start', icon=folium.Icon(color='green')).add_to(route_map)\n",
    "    folium.Marker([dest_lat, dest_lon], tooltip='Destination', icon=folium.Icon(color='red')).add_to(route_map)\n",
    "\n",
    "    # 예측 경로\n",
    "    route_coords = [[lat, lon] for lat, lon in preds_inverse[:, :2]]  # 위도, 경도만 사용\n",
    "    # 예측 경로를 PolyLine으로 시각화\n",
    "    folium.PolyLine(route_coords, color='blue', weight=3, tooltip=\"Predicted Route\").add_to(route_map)\n",
    "\n",
    "    # 예측 경로에 애니메이션 효과 추가\n",
    "    AntPath(route_coords).add_to(route_map)\n",
    "\n",
    "    return route_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "568a7ae6-4167-44c9-8fe5-2a2ffaf2c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과를 역정규화 후 시각화하는 전체 코드\n",
    "def predict_and_visualize(model, initial_seq, dest_lat, dest_lon, scaler, max_steps=2400, distance_threshold=0.3):\n",
    "    preds = predict_autoregressive(model, initial_seq, dest_lat, dest_lon, scaler, max_steps, distance_threshold)\n",
    "    # 역정규화\n",
    "    preds = preds.squeeze(1)\n",
    "    preds_inverse = inverse_transform_preds(preds, scaler)\n",
    "    # 예측 경로 시각화\n",
    "    route_map = visualize_route(initial_seq.numpy(), preds_inverse, dest_lat, dest_lon)\n",
    "\n",
    "    return route_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79138a8c-1d98-4aa2-ad14-b8062fe8f02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1] Predicted: (37.37479, 126.33269) | Target: (33.55000, 126.55000) | ΔLat: 3.82479, ΔLon: 0.21732\n",
      "[Step 11] Predicted: (37.36676, 126.31253) | Target: (33.55000, 126.55000) | ΔLat: 3.81676, ΔLon: 0.23747\n",
      "[Step 21] Predicted: (37.36053, 126.29897) | Target: (33.55000, 126.55000) | ΔLat: 3.81053, ΔLon: 0.25104\n",
      "[Step 31] Predicted: (37.35086, 126.28451) | Target: (33.55000, 126.55000) | ΔLat: 3.80086, ΔLon: 0.26550\n",
      "[Step 41] Predicted: (37.33782, 126.26781) | Target: (33.55000, 126.55000) | ΔLat: 3.78782, ΔLon: 0.28219\n",
      "[Step 51] Predicted: (37.31884, 126.24615) | Target: (33.55000, 126.55000) | ΔLat: 3.76884, ΔLon: 0.30385\n",
      "[Step 61] Predicted: (37.28115, 126.23109) | Target: (33.55000, 126.55000) | ΔLat: 3.73115, ΔLon: 0.31891\n",
      "[Step 71] Predicted: (37.24285, 126.21770) | Target: (33.55000, 126.55000) | ΔLat: 3.69285, ΔLon: 0.33231\n",
      "[Step 81] Predicted: (37.21215, 126.19505) | Target: (33.55000, 126.55000) | ΔLat: 3.66215, ΔLon: 0.35495\n",
      "[Step 91] Predicted: (37.18034, 126.17152) | Target: (33.55000, 126.55000) | ΔLat: 3.63034, ΔLon: 0.37849\n",
      "[Step 101] Predicted: (37.14354, 126.14513) | Target: (33.55000, 126.55000) | ΔLat: 3.59354, ΔLon: 0.40488\n",
      "[Step 111] Predicted: (37.09774, 126.11369) | Target: (33.55000, 126.55000) | ΔLat: 3.54774, ΔLon: 0.43632\n",
      "[Step 121] Predicted: (37.04093, 126.07668) | Target: (33.55000, 126.55000) | ΔLat: 3.49093, ΔLon: 0.47333\n",
      "[Step 131] Predicted: (36.97523, 126.03658) | Target: (33.55000, 126.55000) | ΔLat: 3.42524, ΔLon: 0.51342\n",
      "[Step 141] Predicted: (36.90511, 125.99711) | Target: (33.55000, 126.55000) | ΔLat: 3.35511, ΔLon: 0.55289\n",
      "[Step 151] Predicted: (36.83342, 125.96037) | Target: (33.55000, 126.55000) | ΔLat: 3.28342, ΔLon: 0.58964\n",
      "[Step 161] Predicted: (36.76086, 125.92664) | Target: (33.55000, 126.55000) | ΔLat: 3.21086, ΔLon: 0.62336\n",
      "[Step 171] Predicted: (36.68707, 125.89548) | Target: (33.55000, 126.55000) | ΔLat: 3.13707, ΔLon: 0.65452\n",
      "[Step 181] Predicted: (36.61136, 125.86623) | Target: (33.55000, 126.55000) | ΔLat: 3.06136, ΔLon: 0.68378\n",
      "[Step 191] Predicted: (36.53288, 125.83825) | Target: (33.55000, 126.55000) | ΔLat: 2.98288, ΔLon: 0.71175\n",
      "[Step 201] Predicted: (36.45093, 125.81075) | Target: (33.55000, 126.55000) | ΔLat: 2.90093, ΔLon: 0.73926\n",
      "[Step 211] Predicted: (36.37055, 125.77628) | Target: (33.55000, 126.55000) | ΔLat: 2.82055, ΔLon: 0.77372\n",
      "[Step 221] Predicted: (36.28930, 125.74797) | Target: (33.55000, 126.55000) | ΔLat: 2.73930, ΔLon: 0.80203\n",
      "[Step 231] Predicted: (36.21066, 125.72710) | Target: (33.55000, 126.55000) | ΔLat: 2.66066, ΔLon: 0.82291\n",
      "[Step 241] Predicted: (36.13502, 125.70921) | Target: (33.55000, 126.55000) | ΔLat: 2.58502, ΔLon: 0.84080\n",
      "[Step 251] Predicted: (36.06195, 125.69343) | Target: (33.55000, 126.55000) | ΔLat: 2.51195, ΔLon: 0.85658\n",
      "[Step 261] Predicted: (35.99114, 125.67956) | Target: (33.55000, 126.55000) | ΔLat: 2.44114, ΔLon: 0.87045\n",
      "[Step 271] Predicted: (35.92237, 125.66756) | Target: (33.55000, 126.55000) | ΔLat: 2.37237, ΔLon: 0.88245\n",
      "[Step 281] Predicted: (35.85540, 125.65735) | Target: (33.55000, 126.55000) | ΔLat: 2.30540, ΔLon: 0.89265\n",
      "[Step 291] Predicted: (35.78997, 125.64890) | Target: (33.55000, 126.55000) | ΔLat: 2.23997, ΔLon: 0.90111\n",
      "[Step 301] Predicted: (35.72574, 125.64213) | Target: (33.55000, 126.55000) | ΔLat: 2.17574, ΔLon: 0.90788\n",
      "[Step 311] Predicted: (35.66235, 125.63700) | Target: (33.55000, 126.55000) | ΔLat: 2.11235, ΔLon: 0.91300\n",
      "[Step 321] Predicted: (35.59945, 125.63348) | Target: (33.55000, 126.55000) | ΔLat: 2.04945, ΔLon: 0.91652\n",
      "[Step 331] Predicted: (35.53664, 125.63155) | Target: (33.55000, 126.55000) | ΔLat: 1.98664, ΔLon: 0.91846\n",
      "[Step 341] Predicted: (35.47367, 125.63120) | Target: (33.55000, 126.55000) | ΔLat: 1.92368, ΔLon: 0.91881\n",
      "[Step 351] Predicted: (35.41042, 125.63248) | Target: (33.55000, 126.55000) | ΔLat: 1.86042, ΔLon: 0.91752\n",
      "[Step 361] Predicted: (35.34702, 125.63551) | Target: (33.55000, 126.55000) | ΔLat: 1.79702, ΔLon: 0.91449\n",
      "[Step 371] Predicted: (35.28393, 125.64042) | Target: (33.55000, 126.55000) | ΔLat: 1.73393, ΔLon: 0.90958\n",
      "[Step 381] Predicted: (35.22189, 125.64731) | Target: (33.55000, 126.55000) | ΔLat: 1.67189, ΔLon: 0.90269\n",
      "[Step 391] Predicted: (35.16180, 125.65612) | Target: (33.55000, 126.55000) | ΔLat: 1.61180, ΔLon: 0.89388\n",
      "[Step 401] Predicted: (35.10458, 125.66662) | Target: (33.55000, 126.55000) | ΔLat: 1.55458, ΔLon: 0.88338\n",
      "[Step 411] Predicted: (35.05108, 125.67833) | Target: (33.55000, 126.55000) | ΔLat: 1.50108, ΔLon: 0.87167\n",
      "[Step 421] Predicted: (35.00203, 125.69070) | Target: (33.55000, 126.55000) | ΔLat: 1.45203, ΔLon: 0.85930\n",
      "[Step 431] Predicted: (34.95793, 125.70313) | Target: (33.55000, 126.55000) | ΔLat: 1.40793, ΔLon: 0.84687\n",
      "[Step 441] Predicted: (34.91906, 125.71513) | Target: (33.55000, 126.55000) | ΔLat: 1.36906, ΔLon: 0.83487\n",
      "[Step 451] Predicted: (34.88540, 125.72633) | Target: (33.55000, 126.55000) | ΔLat: 1.33540, ΔLon: 0.82368\n",
      "[Step 461] Predicted: (34.85561, 125.74014) | Target: (33.55000, 126.55000) | ΔLat: 1.30561, ΔLon: 0.80987\n",
      "[Step 471] Predicted: (34.82576, 125.75894) | Target: (33.55000, 126.55000) | ΔLat: 1.27576, ΔLon: 0.79106\n",
      "[Step 481] Predicted: (34.79433, 125.77933) | Target: (33.55000, 126.55000) | ΔLat: 1.24434, ΔLon: 0.77068\n",
      "[Step 491] Predicted: (34.76113, 125.80106) | Target: (33.55000, 126.55000) | ΔLat: 1.21113, ΔLon: 0.74895\n",
      "[Step 501] Predicted: (34.72612, 125.82438) | Target: (33.55000, 126.55000) | ΔLat: 1.17612, ΔLon: 0.72562\n",
      "[Step 511] Predicted: (34.68931, 125.84939) | Target: (33.55000, 126.55000) | ΔLat: 1.13931, ΔLon: 0.70061\n",
      "[Step 521] Predicted: (34.65073, 125.87614) | Target: (33.55000, 126.55000) | ΔLat: 1.10073, ΔLon: 0.67386\n",
      "[Step 531] Predicted: (34.61056, 125.90469) | Target: (33.55000, 126.55000) | ΔLat: 1.06056, ΔLon: 0.64531\n",
      "[Step 541] Predicted: (34.56903, 125.93501) | Target: (33.55000, 126.55000) | ΔLat: 1.01903, ΔLon: 0.61499\n",
      "[Step 551] Predicted: (34.52652, 125.96705) | Target: (33.55000, 126.55000) | ΔLat: 0.97652, ΔLon: 0.58295\n",
      "[Step 561] Predicted: (34.48349, 126.00061) | Target: (33.55000, 126.55000) | ΔLat: 0.93349, ΔLon: 0.54939\n",
      "[Step 571] Predicted: (34.44048, 126.03543) | Target: (33.55000, 126.55000) | ΔLat: 0.89048, ΔLon: 0.51457\n",
      "[Step 581] Predicted: (34.39812, 126.07108) | Target: (33.55000, 126.55000) | ΔLat: 0.84812, ΔLon: 0.47893\n",
      "[Step 591] Predicted: (34.35700, 126.10704) | Target: (33.55000, 126.55000) | ΔLat: 0.80700, ΔLon: 0.44296\n",
      "[Step 601] Predicted: (34.31766, 126.14278) | Target: (33.55000, 126.55000) | ΔLat: 0.76766, ΔLon: 0.40723\n",
      "[Step 611] Predicted: (34.28054, 126.17776) | Target: (33.55000, 126.55000) | ΔLat: 0.73055, ΔLon: 0.37225\n",
      "[Step 621] Predicted: (34.24592, 126.21154) | Target: (33.55000, 126.55000) | ΔLat: 0.69592, ΔLon: 0.33846\n",
      "[Step 631] Predicted: (34.21394, 126.24376) | Target: (33.55000, 126.55000) | ΔLat: 0.66394, ΔLon: 0.30624\n",
      "[Step 641] Predicted: (34.18465, 126.27415) | Target: (33.55000, 126.55000) | ΔLat: 0.63465, ΔLon: 0.27585\n",
      "[Step 651] Predicted: (34.15800, 126.30251) | Target: (33.55000, 126.55000) | ΔLat: 0.60800, ΔLon: 0.24750\n",
      "[Step 661] Predicted: (34.13033, 126.32890) | Target: (33.55000, 126.55000) | ΔLat: 0.58033, ΔLon: 0.22111\n",
      "[Step 671] Predicted: (34.10136, 126.35493) | Target: (33.55000, 126.55000) | ΔLat: 0.55136, ΔLon: 0.19508\n",
      "[Step 681] Predicted: (34.06824, 126.38008) | Target: (33.55000, 126.55000) | ΔLat: 0.51825, ΔLon: 0.16992\n",
      "[Step 691] Predicted: (34.02985, 126.40799) | Target: (33.55000, 126.55000) | ΔLat: 0.47985, ΔLon: 0.14201\n",
      "[Step 701] Predicted: (33.99405, 126.42998) | Target: (33.55000, 126.55000) | ΔLat: 0.44405, ΔLon: 0.12003\n",
      "[Step 711] Predicted: (33.96664, 126.44463) | Target: (33.55000, 126.55000) | ΔLat: 0.41665, ΔLon: 0.10538\n",
      "[Step 721] Predicted: (33.94425, 126.45531) | Target: (33.55000, 126.55000) | ΔLat: 0.39425, ΔLon: 0.09469\n",
      "[Step 731] Predicted: (33.92224, 126.46355) | Target: (33.55000, 126.55000) | ΔLat: 0.37224, ΔLon: 0.08646\n",
      "[Step 741] Predicted: (33.89984, 126.47165) | Target: (33.55000, 126.55000) | ΔLat: 0.34984, ΔLon: 0.07835\n",
      "[Step 751] Predicted: (33.87618, 126.48024) | Target: (33.55000, 126.55000) | ΔLat: 0.32618, ΔLon: 0.06976\n",
      "[Step 761] Predicted: (33.85012, 126.48975) | Target: (33.55000, 126.55000) | ΔLat: 0.30012, ΔLon: 0.06026\n",
      "🚢 목적지 도달 - Step: 762, 12 시간 41 분 소요\n"
     ]
    }
   ],
   "source": [
    "# 예시: 초기 시퀀스와 목적지 좌표로 예측 및 시각화\n",
    "route_map = predict_and_visualize(model, test_input_seq, dest_lat=33.55, dest_lon=126.55, scaler=scaler)\n",
    "route_map.save('predicted_route_map_v2.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
